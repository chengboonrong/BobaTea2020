{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>stime</th>\n",
       "      <th>air_data_value</th>\n",
       "      <th>RH</th>\n",
       "      <th>UGRD</th>\n",
       "      <th>VGRD</th>\n",
       "      <th>HPBL</th>\n",
       "      <th>TMP</th>\n",
       "      <th>goes_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06-011-0007</td>\n",
       "      <td>2019-01-02 20:00:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>-2.106623</td>\n",
       "      <td>-1.797583</td>\n",
       "      <td>256.61905</td>\n",
       "      <td>282.8188</td>\n",
       "      <td>-0.005922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06-019-0500</td>\n",
       "      <td>2019-01-02 20:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>62.200000</td>\n",
       "      <td>1.205877</td>\n",
       "      <td>1.764917</td>\n",
       "      <td>337.49405</td>\n",
       "      <td>281.6313</td>\n",
       "      <td>0.087090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-061-0003</td>\n",
       "      <td>2019-01-02 20:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>1.518377</td>\n",
       "      <td>1.014917</td>\n",
       "      <td>270.61905</td>\n",
       "      <td>280.1313</td>\n",
       "      <td>0.094333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06-073-1201</td>\n",
       "      <td>2019-01-02 20:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.400001</td>\n",
       "      <td>2.080877</td>\n",
       "      <td>-1.610083</td>\n",
       "      <td>1009.30660</td>\n",
       "      <td>288.1938</td>\n",
       "      <td>-0.024185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06-079-2004</td>\n",
       "      <td>2019-01-02 20:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.700000</td>\n",
       "      <td>2.393377</td>\n",
       "      <td>-1.172583</td>\n",
       "      <td>460.43155</td>\n",
       "      <td>285.1938</td>\n",
       "      <td>-0.014013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id                stime  air_data_value         RH      UGRD  \\\n",
       "0  06-011-0007  2019-01-02 20:00:00            17.0  31.600000 -2.106623   \n",
       "1  06-019-0500  2019-01-02 20:00:00            13.0  62.200000  1.205877   \n",
       "2  06-061-0003  2019-01-02 20:00:00            21.0  61.500000  1.518377   \n",
       "3  06-073-1201  2019-01-02 20:00:00             6.0  15.400001  2.080877   \n",
       "4  06-079-2004  2019-01-02 20:00:00             7.0  50.700000  2.393377   \n",
       "\n",
       "       VGRD        HPBL       TMP  goes_measurement  \n",
       "0 -1.797583   256.61905  282.8188         -0.005922  \n",
       "1  1.764917   337.49405  281.6313          0.087090  \n",
       "2  1.014917   270.61905  280.1313          0.094333  \n",
       "3 -1.610083  1009.30660  288.1938         -0.024185  \n",
       "4 -1.172583   460.43155  285.1938         -0.014013  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('new_PM2.5_dataset.csv') # preprocessed and sorted\n",
    "df = pd.read_csv('PM2.5_dataset.csv')\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by station_id and stime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>stime</th>\n",
       "      <th>air_data_value</th>\n",
       "      <th>RH</th>\n",
       "      <th>UGRD</th>\n",
       "      <th>VGRD</th>\n",
       "      <th>HPBL</th>\n",
       "      <th>TMP</th>\n",
       "      <th>goes_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06-011-0007</td>\n",
       "      <td>2019-01-02 20:00:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-2.106623</td>\n",
       "      <td>-1.797583</td>\n",
       "      <td>256.619050</td>\n",
       "      <td>282.81880</td>\n",
       "      <td>-0.005922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>06-011-0007</td>\n",
       "      <td>2019-01-02 21:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>-1.850204</td>\n",
       "      <td>-1.558695</td>\n",
       "      <td>261.172200</td>\n",
       "      <td>283.30810</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>06-011-0007</td>\n",
       "      <td>2019-01-02 22:00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>-1.785869</td>\n",
       "      <td>-0.232563</td>\n",
       "      <td>267.256680</td>\n",
       "      <td>283.81530</td>\n",
       "      <td>-0.036437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>06-011-0007</td>\n",
       "      <td>2019-01-02 23:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>-1.616623</td>\n",
       "      <td>0.305026</td>\n",
       "      <td>216.315490</td>\n",
       "      <td>284.47230</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>06-011-0007</td>\n",
       "      <td>2019-01-03 19:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>-1.234421</td>\n",
       "      <td>0.071434</td>\n",
       "      <td>124.361984</td>\n",
       "      <td>279.52660</td>\n",
       "      <td>0.039313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30418</th>\n",
       "      <td>56-039-1013</td>\n",
       "      <td>2019-08-30 17:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.466133</td>\n",
       "      <td>1.142420</td>\n",
       "      <td>665.376300</td>\n",
       "      <td>287.81610</td>\n",
       "      <td>0.185881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30502</th>\n",
       "      <td>56-039-1013</td>\n",
       "      <td>2019-08-31 16:00:00</td>\n",
       "      <td>5.4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.575478</td>\n",
       "      <td>1.027882</td>\n",
       "      <td>157.645100</td>\n",
       "      <td>285.39597</td>\n",
       "      <td>0.060812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30508</th>\n",
       "      <td>56-039-1013</td>\n",
       "      <td>2019-08-31 17:00:00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>53.8</td>\n",
       "      <td>0.344164</td>\n",
       "      <td>1.428810</td>\n",
       "      <td>567.691600</td>\n",
       "      <td>287.80325</td>\n",
       "      <td>0.226491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30560</th>\n",
       "      <td>56-039-1013</td>\n",
       "      <td>2019-08-31 22:00:00</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.530006</td>\n",
       "      <td>2.375885</td>\n",
       "      <td>1744.444100</td>\n",
       "      <td>294.63544</td>\n",
       "      <td>0.016734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30575</th>\n",
       "      <td>56-039-1013</td>\n",
       "      <td>2019-08-31 23:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4.337727</td>\n",
       "      <td>1.842142</td>\n",
       "      <td>1562.929700</td>\n",
       "      <td>294.14343</td>\n",
       "      <td>0.027831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31570 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id                stime  air_data_value    RH      UGRD  \\\n",
       "0      06-011-0007  2019-01-02 20:00:00            17.0  31.6 -2.106623   \n",
       "11     06-011-0007  2019-01-02 21:00:00            13.0  29.7 -1.850204   \n",
       "21     06-011-0007  2019-01-02 22:00:00            12.0  30.6 -1.785869   \n",
       "30     06-011-0007  2019-01-02 23:00:00             9.0  28.4 -1.616623   \n",
       "81     06-011-0007  2019-01-03 19:00:00            21.0  59.8 -1.234421   \n",
       "...            ...                  ...             ...   ...       ...   \n",
       "30418  56-039-1013  2019-08-30 17:00:00             3.0  55.0  2.466133   \n",
       "30502  56-039-1013  2019-08-31 16:00:00             5.4  66.0 -0.575478   \n",
       "30508  56-039-1013  2019-08-31 17:00:00             4.1  53.8  0.344164   \n",
       "30560  56-039-1013  2019-08-31 22:00:00             4.1  24.1  4.530006   \n",
       "30575  56-039-1013  2019-08-31 23:00:00             2.6  21.4  4.337727   \n",
       "\n",
       "           VGRD         HPBL        TMP  goes_measurement  \n",
       "0     -1.797583   256.619050  282.81880         -0.005922  \n",
       "11    -1.558695   261.172200  283.30810          0.007718  \n",
       "21    -0.232563   267.256680  283.81530         -0.036437  \n",
       "30     0.305026   216.315490  284.47230         -0.050000  \n",
       "81     0.071434   124.361984  279.52660          0.039313  \n",
       "...         ...          ...        ...               ...  \n",
       "30418  1.142420   665.376300  287.81610          0.185881  \n",
       "30502  1.027882   157.645100  285.39597          0.060812  \n",
       "30508  1.428810   567.691600  287.80325          0.226491  \n",
       "30560  2.375885  1744.444100  294.63544          0.016734  \n",
       "30575  1.842142  1562.929700  294.14343          0.027831  \n",
       "\n",
       "[31570 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by =['station_id', 'stime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the column datatype to a suitable datatype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31570 entries, 0 to 31569\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   station_id        31570 non-null  object        \n",
      " 1   stime             31570 non-null  datetime64[ns]\n",
      " 2   air_data_value    31570 non-null  int64         \n",
      " 3   RH                31570 non-null  float64       \n",
      " 4   UGRD              31570 non-null  float64       \n",
      " 5   VGRD              31570 non-null  float64       \n",
      " 6   HPBL              31570 non-null  float64       \n",
      " 7   TMP               31570 non-null  float64       \n",
      " 8   goes_measurement  31570 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df['stime']= pd.to_datetime(df['stime'])\n",
    "df['station_id']= df[\"station_id\"].astype(str)\n",
    "df['air_data_value']= df[\"air_data_value\"].astype('int64')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING \n",
    "#### rescale the EPA air data PM2.5 readings to 1-5 :\n",
    "###### Good/Moderate/Unhealthy for Sensitive Groups/Unhealthy/Very Unhealthy/Hazardous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(df.columns[[0, 1]], axis = 1)\n",
    "new_df.head()\n",
    "\n",
    "new_df['air_data_value'] = np.where((new_df['air_data_value'] >= 0) & (new_df['air_data_value'] <= 50), 0, new_df['air_data_value'])\n",
    "new_df['air_data_value'] = np.where((new_df['air_data_value'] >= 51) & (new_df['air_data_value'] <= 100), 1, new_df['air_data_value'])\n",
    "new_df['air_data_value'] = np.where((new_df['air_data_value'] >= 101) & (new_df['air_data_value'] <= 150), 2, new_df['air_data_value'])\n",
    "new_df['air_data_value'] = np.where((new_df['air_data_value'] >= 151) & (new_df['air_data_value'] <= 250), 3, new_df['air_data_value'])\n",
    "new_df['air_data_value'] = np.where((new_df['air_data_value'] >= 201) & (new_df['air_data_value'] <= 300), 4, new_df['air_data_value'])\n",
    "new_df['air_data_value'] = np.where(new_df['air_data_value'] >= 301, 5, new_df['air_data_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RH</th>\n",
       "      <th>UGRD</th>\n",
       "      <th>VGRD</th>\n",
       "      <th>HPBL</th>\n",
       "      <th>TMP</th>\n",
       "      <th>goes_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.6</td>\n",
       "      <td>-2.107</td>\n",
       "      <td>-1.798</td>\n",
       "      <td>256.619</td>\n",
       "      <td>282.819</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.2</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.765</td>\n",
       "      <td>337.494</td>\n",
       "      <td>281.631</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.5</td>\n",
       "      <td>1.518</td>\n",
       "      <td>1.015</td>\n",
       "      <td>270.619</td>\n",
       "      <td>280.131</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.4</td>\n",
       "      <td>2.081</td>\n",
       "      <td>-1.610</td>\n",
       "      <td>1009.307</td>\n",
       "      <td>288.194</td>\n",
       "      <td>-0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.7</td>\n",
       "      <td>2.393</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>460.432</td>\n",
       "      <td>285.194</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RH   UGRD   VGRD      HPBL      TMP  goes_measurement\n",
       "0  31.6 -2.107 -1.798   256.619  282.819            -0.006\n",
       "1  62.2  1.206  1.765   337.494  281.631             0.087\n",
       "2  61.5  1.518  1.015   270.619  280.131             0.094\n",
       "3  15.4  2.081 -1.610  1009.307  288.194            -0.024\n",
       "4  50.7  2.393 -1.173   460.432  285.194            -0.014"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = new_df.iloc[:, 1:].round(3)\n",
    "Y = new_df.iloc[:, 0].astype(int)\n",
    "\n",
    "num_X = X.to_numpy()\n",
    "num_Y = Y.to_numpy()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: air_data_value, dtype: int32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE TRAINING AND TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(num_X, num_Y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import statsmodels.api as sm\n",
    "\n",
    "scaler = preprocessing.RobustScaler() # Features Scaling is required for distance-based algorithms\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML MODEL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests\n",
    "regr_rf = RandomForestRegressor(max_depth=20, random_state=42,\n",
    "                             n_estimators=250)\n",
    "# regr_rf = RandomForestRegressor()\n",
    "regr_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training score: 91.82000000000001, testing score: 52.059999999999995'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = regr_rf.score(X_train, y_train)\n",
    "test_score = regr_rf.score(X_test, y_test)\n",
    "\"training score: {}, testing score: {}\".format(train_score.round(4)*100, test_score.round(4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE THE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# # Save the Modle to file in the current working directory\n",
    "# Pkl_Filename = \"PM2.5_model_updated.pkl\"  \n",
    "# with open(Pkl_Filename, 'wb') as file:  \n",
    "#     pickle.dump(regr_rf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE PRETRAINED MODEL AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "with open(\"PM2.5_model_updated.pkl\", 'rb') as file:  \n",
    "    Pickled_LR_Model = pickle.load(file)\n",
    "Pickled_LR_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training score: 91.82000000000001, testing score: 52.059999999999995'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = Pickled_LR_Model.score(X_train, y_train)\n",
    "test_score = Pickled_LR_Model.score(X_test, y_test)\n",
    "\"training score: {}, testing score: {}\".format(train_score.round(4)*100, test_score.round(4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = num_Y\n",
    "y_pred = Pickled_LR_Model.predict(num_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSERT NEW DATA FROM AQS WEBSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "# res = re.get('https://aqs.epa.gov/data/api/monitors/bySite?email=test@aqs.api&key=test&param=88101&bdate=20190101&edate=20191231&state={}&county={}&site={}'.format(stations_ids[0][0], stations_ids[0][1], stations_ids[0][2]))\n",
    "# data = res.json()['Data'][0]\n",
    "\n",
    "# res = re.get('https://aqs.epa.gov/data/api/monitors/bySite?email=test@aqs.api&key=test&param=88101&bdate=20190101&edate=20191231&state={}&county={}&site={}'.format(stations_ids[0][0], stations_ids[0][1], stations_ids[0][2]))\n",
    "station_ids = df['station_id']\n",
    "stations_ids = [sid.split('-') for sid in station_ids]\n",
    "\n",
    "def form(i, data):\n",
    "    return [station_ids[i], data['latitude'], data['longitude'], data['local_site_name'], data['address'], data['state_name'], data['county_name'], data['city_name']]\n",
    "\n",
    "db = []\n",
    "print(len(stations_ids))\n",
    "for i, sid in enumerate(stations_ids):\n",
    "    print(i)\n",
    "    res = re.get('https://aqs.epa.gov/data/api/monitors/bySite?email=chengchris8715@gmail.com&key=greyfrog63&param=88101&bdate=20190101&edate=20191231&state={}&county={}&site={}'.format(stations_ids[i][0], stations_ids[i][1], stations_ids[i][2]))\n",
    "    data = res.json()['Data'][0]\n",
    "    db.append(form(i, data))\n",
    "    \n",
    "len(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = pd.DataFrame(data=db, columns=['station_id', 'latitude', 'longitude', 'local_site_name', 'address', 'state_name', 'county_name', 'city_name'])\n",
    "new_new_df = pd.merge(df, ndf)\n",
    "new_new_df.to_csv('new_PM2.5_dataset.csv', index=None)\n",
    "new_new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nndf = pd.read_csv('new_PM2.5_dataset.csv')\n",
    "nndf.head()\n",
    "\n",
    "nndf['predicted_air_pollution_level'] = y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nndf.head()\n",
    "nndf.to_csv('new_new_PM2.5_dataset.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Nebraska', 'Nevada', 'Oregon', 'Texas', 'Missouri',\n",
       "       'New Mexico', 'Rhode Island', 'Pennsylvania', 'Oklahoma', 'Kansas',\n",
       "       'South Carolina', 'District Of Columbia', 'Utah', 'Idaho',\n",
       "       'Wyoming', 'Colorado', 'Montana'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndf.state_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
